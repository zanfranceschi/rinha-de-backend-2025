services:
  api1: &api
    image: lhuizf/rinha-de-backend-2025-bun:0.4.0
    hostname: api1
    container_name: api1
    environment:
      - PORT=3333
      - REDIS_URL=redis://redis:6379
    networks:
      - backend
    depends_on:
      redis:
        condition: service_healthy
    command: ["bun", "run", "src/index.ts"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3333/health"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: "0.30"
          memory: "75MB"

  api2:
    <<: *api
    hostname: api2
    container_name: api2

  worker1: &worker
    image: lhuizf/rinha-de-backend-2025-bun:0.4.0
    hostname: worker1
    container_name: worker1
    environment:
      - REDIS_URL=redis://redis:6379
      - PROCESSOR_DEFAULT_URL=http://payment-processor-default:8080
      - PROCESSOR_FALLBACK_URL=http://payment-processor-fallback:8080
      - QUEUE_CONCURRENCY=200
    networks:
      - backend
      - payment-processor
    depends_on:
      redis:
        condition: service_healthy
      api1:
        condition: service_healthy
    command: ["bun", "run", "src/worker.ts"]
    deploy:
      resources:
        limits:
          cpus: "0.35"
          memory: "85MB"

  worker2:
    <<: *worker
    hostname: worker2
    container_name: worker2
    depends_on:
      redis:
        condition: service_healthy
      api2:
        condition: service_healthy

  redis:
    image: redis:7.2-alpine
    container_name: redis
    command:
      [
        "redis-server",
        "--save",
        "",
        "--appendonly",
        "no",
        "--maxclients",
        "20000",
        "--tcp-backlog",
        "511",
        "--dynamic-hz",
        "yes",
      ]
    networks:
      - backend
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: "0.15"
          memory: "20MB"

  load-balancer:
    image: nginx:1.25.2-alpine
    container_name: load-balancer
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "9999:9999"
    networks:
      - backend
    depends_on:
      - api1
      - api2
    deploy:
      resources:
        limits:
          cpus: "0.05"
          memory: "10MB"

networks:
  backend:
    name: backend
    driver: bridge
  payment-processor:
    external: true
